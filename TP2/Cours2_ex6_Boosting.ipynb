{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies de base\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Graphes\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Eviter les Deprecated warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création et affichage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=800, noise=0.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)\n",
    "plt.scatter(X[:,0],X[:,1], c = y,cmap='plasma');\n",
    "plt.title('make_moons noise=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle et apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=100,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.3, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage d'un arbre aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_tree=random.randint(0,99)\n",
    "print('Arbre N°',rd_tree)\n",
    "\n",
    "export_graphviz(ada_clf.estimators_[rd_tree],\n",
    "                feature_names=['x1','x2'],\n",
    "                out_file = 'tree.dot',\n",
    "                filled=True,\n",
    "                rounded=True)\n",
    "\n",
    "#appel à la fonction dot de graphwiz\n",
    "os.system(\"dot -Tpng tree.dot -o tree.png\")    \n",
    "#Affichage de l'image créée\n",
    "Image(\"tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True,showlabel=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    if showlabel:\n",
    "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\", alpha=alpha)\n",
    "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"ys\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "print('score Adaboost :' , accuracy_score(y_test, y_pred_ada))\n",
    "plt.figure(figsize=(21,8))\n",
    "plot_decision_boundary(ada_clf, X, y)\n",
    "plt.title(\"Adaptative Boosting\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple Gradient Boosting avec ou sans Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On passe à 80000 pour mieux voir, sinon on aura trop peu d'itérations\n",
    "X, y = make_moons(n_samples=80000, noise=0.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43)\n",
    "\n",
    "# warm_start=True permet de garder l'ensemble puis de le relancer\n",
    "gb_clf = GradientBoostingClassifier(max_depth=2, warm_start=True, random_state=42)\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "# Test jusqu'à 50 estimateurs\n",
    "for n_estimators in range(1, 50):    \n",
    "    gb_clf.n_estimators = n_estimators\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    y_pred = gb_clf.predict(X_test)\n",
    "    val_error = accuracy_score(y_test, y_pred)\n",
    "    print(n_estimators,':',val_error)\n",
    "    # Test de la variation de l'erreur\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        #Si plus de 5 augmentations, on sort.\n",
    "        if error_going_up == 5:\n",
    "            print('nombre optimal estimateur:', n_estimators)\n",
    "            break  # early stopping\n",
    "gb_clf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#On passe à 80000 pour mieux voir, sinon on aura trop peu d'itérations\n",
    "X, y = make_moons(n_samples=80000, noise=0.3, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, random_state=43)\n",
    "\n",
    "n_estimators=500\n",
    "\n",
    "# Si pas d'amélioration > 0.0001 sur les 5 derniers estimateurs => Arrêt\n",
    "gbes = GradientBoostingClassifier(\n",
    "    n_estimators=n_estimators,   \n",
    "    n_iter_no_change=5, \n",
    "    tol=0.0001,\n",
    "    random_state=0\n",
    "    )\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    random_state=0\n",
    "    )\n",
    "    \n",
    "start = time.time()\n",
    "gb.fit(X_train, y_train)\n",
    "time_gb=(time.time() - start)\n",
    "\n",
    "start = time.time()\n",
    "gbes.fit(X_train, y_train)\n",
    "time_gbes=(time.time() - start)\n",
    "\n",
    "score_gb =gb.score(X_dev, y_dev)\n",
    "score_gbes= gbes.score(X_dev, y_dev)\n",
    "\n",
    "n_gb=gb.n_estimators_\n",
    "n_gbes=gbes.n_estimators_\n",
    "\n",
    "dict_result = {\n",
    "    \"scores\":[score_gb * 100,score_gbes * 100],\n",
    "    \"estimateurs\":[n_gb,n_gbes],\n",
    "    \"temps\":[time_gb,time_gbes]\n",
    "}\n",
    "\n",
    "pd.DataFrame(dict_result,index=['Normal','Early stopping']).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage Résultat Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient = gb_clf.predict(X_test)    \n",
    "print('score Gradient Boosting :' , accuracy_score(y_test, y_pred_gradient))\n",
    "plt.figure(figsize=(21,8))\n",
    "plot_decision_boundary(gb_clf, X, y,showlabel=False)\n",
    "plt.title(\"Gradient Boosting\", fontsize=14)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}