{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Random Forest / Boosting appliquésau Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lecture des fichiers de données\n",
    "1.1 Lire le Dataframe train (avec le champs Survived). Afficher les 10 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Lire le Dataframe test (sans le champs Survived) dans les fichiers train_clean.csv. Afficher les 10 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Préparation des données de Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Charger les features d'apprentissage dans un array numpy X_alltrain. Afficher le type de X_alltrain les 10 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Charger les labels dans un array numpy y_alltrain. Afficher les 10 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 Séparer les features et les labels en deux parties (train et dev). afficher les nombres de lignes et de colonnes pour les 4 arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.6 Afficher les noms des features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions permettant de générer le fichier d'envoi à Kaggle\n",
    "#parametres: Classifiers; Données à calculer ; index)\n",
    "\n",
    "def generer_resultats(clf,df_test=test):\n",
    "    \"\"\"\n",
    "    Fonctions permettant de générer le fichier d'envoi à Kaggle.\n",
    "    On passe un classifier sur lequel on refait le training avec toutes les données de training\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Classifiers : Classifier utilisé pour la prédiction\n",
    "    data : Données à calculer. par défaut, les valeurs du dataset \"test\"\n",
    "    idx : Index des passagers testés. Stockés dans finalfile_index lors de la lecture des données\n",
    "    \"\"\"    \n",
    "    data = df_test.iloc[:,1:].values\n",
    "    idx = df_test.PassengerId\n",
    "    print(clf.get_params())\n",
    "    clf.fit(X_alltrain, y_alltrain)\n",
    "    prediction=clf.predict(data)\n",
    "    results=pd.DataFrame(prediction.astype(int), index = df_test.PassengerId, columns=['Survived'])\n",
    "    results.to_csv('resultats%s.csv'%clf.__class__.__name__)\n",
    "    \n",
    "#Fonction pour l'affichage 2 D des résultats    \n",
    "\n",
    "def plot_decision_boundary(clf,X,y, axes=[-0, 30, -5, 5], axis_name=['x1','x2'],alpha=0.5, contour=True):\n",
    "    \"\"\"\n",
    "    Fonction pour l'affichage 2 D des résultats   \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : Classifier à afficher\n",
    "    X : features de Données a afficher\n",
    "    y : labels de Données a afficher  \n",
    "    axes : : Tailles des axes (valeur min/max)\n",
    "    axis_name : Nom des axes sur le graphique\n",
    "    alpha : Transparence des points\n",
    "    contour : Afichage du contour\n",
    "    \"\"\"     \n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\",label=\"Disparu\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"ys\", label=\"Rescapé\",alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(axis_name[0], fontsize=18)\n",
    "    plt.ylabel(axis_name[1]+ \"  \",fontsize=18, rotation=0)    \n",
    "    plt.legend(loc=\"lower right\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Arbre de Décision\n",
    "2.1 En utilisant l'exemple 1, contruisez et entrainez un arbre de décision pour prévoir la survie. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Appliquer le modèle sur vos données de Dev. Afficher la précision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 : Essayez plusieurs valeurs pour max_depth et garder le meilleur résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 : Affichez l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Générez le fichier de résultats et envoyer une soumission sur Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Question : Quel est votre meilleur score et Classement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Random Forest\n",
    "3.1 En utilisant l'exemple 5, Réalisez un algorithme de Random Forest sur les données Titanic. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Classez les features par ordre d'importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Tester dans une boucle différentes valeurs pour max_depth et max_features de l'arbre et pour le nombre d'estimateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Générer un fichier et envoyer les résultats sur Kaggle. Ecrivez ici vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generer_resultats(rnd_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 En utilisant la fonction plot_decision_boundary, afficher les résultats pour de l'arbre seul et du modèle de forêt les variables Fare et Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 : Boosting\n",
    "4.1 En vous inspirant de l'exemple 6, Testez ici Adaboost et le gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Afficher les résultats. Essayer differents paramètres de Learning Rate, nombre d'estimateurs, taille des arbres ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Appliquez le \"Early Stopping\" sur le nombre d'estimateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Générer un fichier et envoyer les résultats sur Kaggle. Ecrivez ici vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generer_resultats(gbes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
